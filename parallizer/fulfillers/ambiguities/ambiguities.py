"""Ambiguities fulfiller for generating context-aware search queries."""

from parallizer.utils import get_lm
from parallizer.signatures.rg_query_generator import RGQueryGenerator
from parallizer.signatures.question_ambiguity_signature import QuestionAmbiguityIdentifier
from parallizer.fulfillers.base import Fulfiller
from shared.models import Card, CardType
from shared.context import GlobalPreferenceContext
from parallizer.utils.ripgrep import RipgrepSearch, SearchResult
from typing import List, Tuple, Optional
from abc import ABCMeta
from pathlib import Path
import dspy
import logging

logger = logging.getLogger("parallax.ambiguities")


# Create a combined metaclass to resolve the conflict between ABCMeta and dspy.Module's metaclass
class CombinedMeta(ABCMeta, type(dspy.Module)):
    """Combined metaclass for classes that inherit from both ABC and dspy.Module."""
    pass


class Ambiguities(Fulfiller, dspy.Module, metaclass=CombinedMeta):
    """
    Ambiguities fulfiller that generates context-aware search queries and identifies ambiguities.

    Uses DSPy to:
    1. Generate intelligent ripgrep queries based on the current document
    2. Perform code searches to find relevant context
    3. Analyze search results against plan to identify questions and ambiguities
    """

    def __init__(self, **kwargs):
        """Initialize the Ambiguities fulfiller with DSPy module setup."""
        super().__init__(**kwargs)
        logger.info("Initializing Ambiguities fulfiller")
        lm = get_lm()
        if lm is not None:
            logger.info("LM configured successfully")
        else:
            logger.warning("No LM available for Ambiguities fulfiller")
        self.query_generator = dspy.Predict(RGQueryGenerator)
        self.question_identifier = dspy.Predict(QuestionAmbiguityIdentifier)
        self.search_backend = RipgrepSearch()

    async def forward(
        self,
        document_text: str,
        cursor_position: Tuple[int, int],
        global_context: GlobalPreferenceContext,
        intent_label: Optional[str] = None,
        **kwargs
    ) -> List[Card]:
        """
        Forward pass for ambiguities fulfiller - generates questions and identifies ambiguities.

        Args:
            document_text: The entire text content of the current document
            cursor_position: (line, column) position of the parser/cursor
            global_context: Global preference context containing scope root and plan path
            intent_label: Optional LLM-generated intent or label describing the query
            **kwargs: Additional parameters

        Returns:
            List of Card objects with QUESTION type containing identified ambiguities
        """
        logger.info(f"Ambiguities fulfiller invoked at {cursor_position}, scope_root={global_context.scope_root}, plan_path={global_context.plan_path}")

        # Build cursor context and repo summary
        line, col = cursor_position
        lines = document_text.split('\n')
        cursor_context = self._build_cursor_context(lines, line, col)

        repo_summary = f"Repository at {global_context.scope_root}"
        if global_context.plan_path:
            repo_summary += f", Plan file: {global_context.plan_path}"

        # Generate queries using DSPy Predict module
        logger.info("Invoking DSPy query generator")
        query_result = self.query_generator(
            current_document=document_text,
            repo_summary=repo_summary
        )

        # Log the generated queries
        if not query_result.queries:
            logger.warning("No queries generated by query generator")
            return []

        logger.info(f"Generated {len(query_result.queries)} queries: {query_result.queries}")

        # Perform searches in parallel for all queries
        logger.info("Executing all code searches in parallel...")
        search_tasks = [
            self.search_backend.search(
                query=query,
                directory=global_context.scope_root,
                max_results=10,  # Limit results per query
                context_lines=2,
                case_sensitive=False
            )
            for query in query_result.queries
        ]

        # Execute all searches concurrently
        import asyncio
        search_results = await asyncio.gather(*search_tasks, return_exceptions=True)

        # Process results and filter out exceptions
        all_search_results: List[SearchResult] = []
        for i, result in enumerate(search_results):
            query = query_result.queries[i]

            if isinstance(result, Exception):
                logger.error(f"Search failed for query '{query}': {result}")
                # Create failed search result
                all_search_results.append(SearchResult(
                    success=False,
                    query=query,
                    total_matches=0,
                    matches=[],
                    error=str(result)
                ))
            else:
                logger.info(f"Search result for '{query}': success={result.success}, total_matches={result.total_matches}")
                if result.error:
                    logger.warning(f"Search error: {result.error}")
                all_search_results.append(result)

        # Combine all search results into a formatted string
        combined_context = self._combine_search_results(all_search_results)
        logger.debug(f"Combined search results length: {len(combined_context)} characters")

        # Read plan file if available
        plan_content = ""
        if global_context.plan_path:
            try:
                plan_path = Path(global_context.plan_path)
                if plan_path.exists() and plan_path.is_file():
                    plan_content = plan_path.read_text()
                    logger.info(f"Read plan file: {global_context.plan_path} ({len(plan_content)} characters)")
                else:
                    logger.warning(f"Plan file not found or not a file: {global_context.plan_path}")
            except Exception as e:
                logger.error(f"Failed to read plan file: {e}")

        # If no plan content, use document text as fallback
        if not plan_content:
            plan_content = document_text
            logger.info("Using document text as plan content (no plan file provided)")

        # Invoke question identifier to find ambiguities
        logger.info("Invoking DSPy question identifier")
        ambiguity_result = self.question_identifier(
            relevant_code_context=combined_context,
            current_plan=plan_content
        )

        # Convert output questions to QUESTION cards
        cards = []
        if ambiguity_result.output_ambiguities_questions:
            logger.info(f"Identified {len(ambiguity_result.output_ambiguities_questions)} ambiguities/questions")
            for i, question in enumerate(ambiguity_result.output_ambiguities_questions, 1):
                card = Card(
                    header="Question",
                    text=question,
                    type=CardType.QUESTION,
                    metadata={
                        "source": "ambiguities",
                        "plan_path": global_context.plan_path,
                        "question_number": i
                    }
                )
                cards.append(card)
        else:
            logger.info("No ambiguities or questions identified")

        logger.info(f"Generated {len(cards)} question cards")
        return cards

    def _combine_search_results(self, search_results: List[SearchResult]) -> str:
        """
        Combine multiple SearchResult objects into a single formatted string.

        Args:
            search_results: List of SearchResult objects

        Returns:
            Formatted string containing all search results
        """
        if not search_results:
            return "No search results available."

        combined_parts = []
        for i, result in enumerate(search_results, 1):
            if result.success and result.matches:
                combined_parts.append(f"=== Search Query {i}: {result.query} ===")
                combined_parts.append(result.to_formatted_string())
                combined_parts.append("")  # Empty line between results

        if not combined_parts:
            return "All searches returned no results."

        return "\n".join(combined_parts)

    def _build_cursor_context(self, lines: List[str], line: int, col: int) -> str:
        """Build cursor context window with <cursor> marker."""
        if line < 0 or line >= len(lines):
            return "<cursor>"

        current_line = lines[line]
        # Insert <cursor> marker at column position
        before_cursor = current_line[:col]
        after_cursor = current_line[col:]
        context_line = before_cursor + "<cursor>" + after_cursor

        # Try to include surrounding lines if within 150 char limit
        context = context_line
        if line > 0:
            prev_line = lines[line - 1]
            if len(prev_line + "\n" + context) <= 150:
                context = prev_line + "\n" + context

        if line < len(lines) - 1:
            next_line = lines[line + 1]
            if len(context + "\n" + next_line) <= 150:
                context = context + "\n" + next_line

        return context[:150]

    async def is_available(self) -> bool:
        """Check if ambiguities fulfiller is available."""
        from parallizer.utils import get_lm
        lm_available = get_lm() is not None
        ripgrep_available = await self.search_backend.is_available()
        available = lm_available and ripgrep_available
        logger.info(f"Ambiguities fulfiller availability check: LM={lm_available}, ripgrep={ripgrep_available}, overall={available}")
        return available
