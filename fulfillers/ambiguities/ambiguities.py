"""Ambiguities fulfiller for generating context-aware search queries."""

from utils import get_lm
from signatures.query_generator import RGQueryGenerator
from fulfillers.base import Fulfiller
from fulfillers.models import Card, CardType
from utils.context import GlobalPreferenceContext
from utils.ripgrep import RipgrepSearch, SearchResult
from typing import List, Tuple, Optional
from abc import ABCMeta
import dspy
import logging

logger = logging.getLogger("parallax.ambiguities")

dspy.configure(lm=get_lm())


# Create a combined metaclass to resolve the conflict between ABCMeta and dspy.Module's metaclass
class CombinedMeta(ABCMeta, type(dspy.Module)):
    """Combined metaclass for classes that inherit from both ABC and dspy.Module."""
    pass


class Ambiguities(Fulfiller, dspy.Module, metaclass=CombinedMeta):
    """
    Ambiguities fulfiller that generates context-aware search queries.

    Uses DSPy to generate intelligent ripgrep queries based on the current document
    and cursor context, then performs code searches to find relevant context.
    """

    def __init__(self, **kwargs):
        """Initialize the Ambiguities fulfiller with DSPy module setup."""
        super().__init__(**kwargs)
        logger.info("Initializing Ambiguities fulfiller")
        lm = get_lm()
        if lm is not None:
            logger.info("LM configured successfully")
            dspy.configure(lm=lm)
        else:
            logger.warning("No LM available for Ambiguities fulfiller")
        self.predictor = dspy.Predict(RGQueryGenerator)
        self.search_backend = RipgrepSearch()

    def forward(
        self,
        document_text: str,
        cursor_position: Tuple[int, int],
        global_context: GlobalPreferenceContext,
        intent_label: Optional[str] = None,
        **kwargs
    ) -> List[Card]:
        """
        Forward pass for ambiguities DSPy module.

        Args:
            document_text: The entire text content of the current document
            cursor_position: (line, column) position of the parser/cursor
            global_context: Global preference context containing scope root and plan path
            intent_label: Optional LLM-generated intent or label describing the query
            **kwargs: Additional parameters

        Returns:
            List of Card objects with search results
        """
        logger.debug(f"Generating queries at cursor position {cursor_position}")

        # Build cursor context window (â‰¤150 characters)
        line, col = cursor_position
        lines = document_text.split('\n')
        cursor_context = self._build_cursor_context(lines, line, col)
        logger.debug(f"Cursor context: {cursor_context[:100]}...")

        # Generate repo summary (for now, just use a simple default)
        # TODO: Could be enhanced to read README or project structure
        repo_summary = f"Repository at {global_context.scope_root}"
        if global_context.plan_path:
            repo_summary += f", Plan file: {global_context.plan_path}"

        # Generate queries using DSPy Predict module
        logger.info("Invoking DSPy predictor for query generation")
        result = self.predictor(
            current_document=document_text,
            repo_summary=repo_summary
        )

        # Log the generated queries
        if result.queries:
            logger.info(f"Generated {len(result.queries)} queries: {result.queries}")
        else:
            logger.warning("No queries generated by predictor")
            return []

        # Perform searches for each query
        cards = []
        for query in result.queries:
            logger.info(f"Executing search for query: {query}")

            # Run the search synchronously (we're in a forward method, not async)
            # We'll need to handle this properly in invoke
            # For now, just log that we would search
            logger.info(f"Would search for: {query} in {global_context.scope_root}")

        return cards

    async def invoke(
        self,
        document_text: str,
        cursor_position: Tuple[int, int],
        global_context: GlobalPreferenceContext,
        intent_label: Optional[str] = None,
        **kwargs
    ) -> List[Card]:
        """
        Invoke ambiguities fulfiller (delegates to forward and performs searches).

        Args:
            document_text: The entire text content of the current document
            cursor_position: (line, column) position of the parser/cursor
            global_context: Global preference context containing scope root and plan path
            intent_label: Optional LLM-generated intent or label describing the query
            **kwargs: Additional parameters

        Returns:
            List of Card objects with search results
        """
        logger.info(f"Ambiguities fulfiller invoked at {cursor_position}, scope_root={global_context.scope_root}, plan_path={global_context.plan_path}")

        # Build cursor context and repo summary
        line, col = cursor_position
        lines = document_text.split('\n')
        cursor_context = self._build_cursor_context(lines, line, col)

        repo_summary = f"Repository at {global_context.scope_root}"
        if global_context.plan_path:
            repo_summary += f", Plan file: {global_context.plan_path}"

        # Generate queries using DSPy Predict module
        logger.info("Invoking DSPy predictor for query generation")
        result = self.predictor(
            current_document=document_text,
            repo_summary=repo_summary
        )

        # Log the generated queries
        if result.queries:
            logger.info(f"Generated {len(result.queries)} queries: {result.queries}")
        else:
            logger.warning("No queries generated by predictor")
            return []

        # Perform searches for each query
        cards = []
        for query in result.queries:
            logger.info(f"Executing search for query: {query}")

            # Perform the async search
            search_result: SearchResult = await self.search_backend.search(
                query=query,
                directory=global_context.scope_root,
                max_results=10,  # Limit results per query
                context_lines=2,
                case_sensitive=False
            )

            # Log the search result
            logger.info(f"Search result for '{query}': success={search_result.success}, total_matches={search_result.total_matches}")
            if search_result.error:
                logger.warning(f"Search error: {search_result.error}")

            # Convert search results to cards
            if search_result.success and search_result.matches:
                for match in search_result.matches[:5]:  # Limit to 5 matches per query
                    # Format the card text with context
                    text_lines = []
                    if match.context_before:
                        text_lines.extend([f"  {line}" for line in match.context_before])
                    text_lines.append(f"> {match.line_content}")
                    if match.context_after:
                        text_lines.extend([f"  {line}" for line in match.context_after])

                    card = Card(
                        header=f"{match.file_path}:{match.line_number}",
                        text="\n".join(text_lines),
                        type=CardType.CONTEXT,
                        metadata={
                            "file_path": match.file_path,
                            "line_number": match.line_number,
                            "query": query,
                            "source": "ambiguities"
                        }
                    )
                    cards.append(card)

        logger.info(f"Generated {len(cards)} context cards from searches")
        return cards

    def _build_cursor_context(self, lines: List[str], line: int, col: int) -> str:
        """Build cursor context window with <cursor> marker."""
        if line < 0 or line >= len(lines):
            return "<cursor>"

        current_line = lines[line]
        # Insert <cursor> marker at column position
        before_cursor = current_line[:col]
        after_cursor = current_line[col:]
        context_line = before_cursor + "<cursor>" + after_cursor

        # Try to include surrounding lines if within 150 char limit
        context = context_line
        if line > 0:
            prev_line = lines[line - 1]
            if len(prev_line + "\n" + context) <= 150:
                context = prev_line + "\n" + context

        if line < len(lines) - 1:
            next_line = lines[line + 1]
            if len(context + "\n" + next_line) <= 150:
                context = context + "\n" + next_line

        return context[:150]

    async def is_available(self) -> bool:
        """Check if ambiguities fulfiller is available."""
        from utils import get_lm
        lm_available = get_lm() is not None
        ripgrep_available = await self.search_backend.is_available()
        available = lm_available and ripgrep_available
        logger.info(f"Ambiguities fulfiller availability check: LM={lm_available}, ripgrep={ripgrep_available}, overall={available}")
        return available
