"""Ambiguities fulfiller for generating context-aware search queries."""

from utils import get_lm
from signatures.rg_query_generator import RGQueryGenerator
from signatures.question_ambiguity_signature import QuestionAmbiguityIdentifier
from fulfillers.base import Fulfiller
from fulfillers.models import Card, CardType
from utils.context import GlobalPreferenceContext
from utils.ripgrep import RipgrepSearch, SearchResult
from typing import List, Tuple, Optional
from abc import ABCMeta
from pathlib import Path
import dspy
import logging

logger = logging.getLogger("parallax.ambiguities")

dspy.configure(lm=get_lm())


# Create a combined metaclass to resolve the conflict between ABCMeta and dspy.Module's metaclass
class CombinedMeta(ABCMeta, type(dspy.Module)):
    """Combined metaclass for classes that inherit from both ABC and dspy.Module."""
    pass


class Ambiguities(Fulfiller, dspy.Module, metaclass=CombinedMeta):
    """
    Ambiguities fulfiller that generates context-aware search queries and identifies ambiguities.

    Uses DSPy to:
    1. Generate intelligent ripgrep queries based on the current document
    2. Perform code searches to find relevant context
    3. Analyze search results against plan to identify questions and ambiguities
    """

    def __init__(self, **kwargs):
        """Initialize the Ambiguities fulfiller with DSPy module setup."""
        super().__init__(**kwargs)
        logger.info("Initializing Ambiguities fulfiller")
        lm = get_lm()
        if lm is not None:
            logger.info("LM configured successfully")
            dspy.configure(lm=lm)
        else:
            logger.warning("No LM available for Ambiguities fulfiller")
        self.query_generator = dspy.Predict(RGQueryGenerator)
        self.question_identifier = dspy.Predict(QuestionAmbiguityIdentifier)
        self.search_backend = RipgrepSearch()

    def forward(
        self,
        document_text: str,
        cursor_position: Tuple[int, int],
        global_context: GlobalPreferenceContext,
        intent_label: Optional[str] = None,
        **kwargs
    ) -> List[Card]:
        """
        Forward pass for ambiguities DSPy module.

        Args:
            document_text: The entire text content of the current document
            cursor_position: (line, column) position of the parser/cursor
            global_context: Global preference context containing scope root and plan path
            intent_label: Optional LLM-generated intent or label describing the query
            **kwargs: Additional parameters

        Returns:
            List of Card objects with search results
        """
        logger.debug(f"Generating queries at cursor position {cursor_position}")

        # Build cursor context window (â‰¤150 characters)
        line, col = cursor_position
        lines = document_text.split('\n')
        cursor_context = self._build_cursor_context(lines, line, col)
        logger.debug(f"Cursor context: {cursor_context[:100]}...")

        # Generate repo summary (for now, just use a simple default)
        # TODO: Could be enhanced to read README or project structure
        repo_summary = f"Repository at {global_context.scope_root}"
        if global_context.plan_path:
            repo_summary += f", Plan file: {global_context.plan_path}"

        # Generate queries using DSPy Predict module
        logger.info("Invoking DSPy predictor for query generation")
        result = self.predictor(
            current_document=document_text,
            repo_summary=repo_summary
        )

        # Log the generated queries
        if result.queries:
            logger.info(f"Generated {len(result.queries)} queries: {result.queries}")
        else:
            logger.warning("No queries generated by predictor")
            return []

        # Perform searches for each query
        cards = []
        for query in result.queries:
            logger.info(f"Executing search for query: {query}")

            # Run the search synchronously (we're in a forward method, not async)
            # We'll need to handle this properly in invoke
            # For now, just log that we would search
            logger.info(f"Would search for: {query} in {global_context.scope_root}")

        return cards

    async def invoke(
        self,
        document_text: str,
        cursor_position: Tuple[int, int],
        global_context: GlobalPreferenceContext,
        intent_label: Optional[str] = None,
        **kwargs
    ) -> List[Card]:
        """
        Invoke ambiguities fulfiller (delegates to forward and performs searches).

        Args:
            document_text: The entire text content of the current document
            cursor_position: (line, column) position of the parser/cursor
            global_context: Global preference context containing scope root and plan path
            intent_label: Optional LLM-generated intent or label describing the query
            **kwargs: Additional parameters

        Returns:
            List of Card objects with QUESTION type containing identified ambiguities
        """
        logger.info(f"Ambiguities fulfiller invoked at {cursor_position}, scope_root={global_context.scope_root}, plan_path={global_context.plan_path}")

        # Build cursor context and repo summary
        line, col = cursor_position
        lines = document_text.split('\n')
        cursor_context = self._build_cursor_context(lines, line, col)

        repo_summary = f"Repository at {global_context.scope_root}"
        if global_context.plan_path:
            repo_summary += f", Plan file: {global_context.plan_path}"

        # Generate queries using DSPy Predict module
        logger.info("Invoking DSPy query generator")
        query_result = self.query_generator(
            current_document=document_text,
            repo_summary=repo_summary
        )

        # Log the generated queries
        if not query_result.queries:
            logger.warning("No queries generated by query generator")
            return []

        logger.info(f"Generated {len(query_result.queries)} queries: {query_result.queries}")

        # Perform searches for each query and collect all results
        all_search_results: List[SearchResult] = []
        for query in query_result.queries:
            logger.info(f"Executing search for query: {query}")

            # Perform the async search
            search_result: SearchResult = await self.search_backend.search(
                query=query,
                directory=global_context.scope_root,
                max_results=10,  # Limit results per query
                context_lines=2,
                case_sensitive=False
            )

            # Log the search result
            logger.info(f"Search result for '{query}': success={search_result.success}, total_matches={search_result.total_matches}")
            if search_result.error:
                logger.warning(f"Search error: {search_result.error}")

            all_search_results.append(search_result)

        # Combine all search results into a formatted string
        combined_context = self._combine_search_results(all_search_results)
        logger.debug(f"Combined search results length: {len(combined_context)} characters")

        # Read plan file if available
        plan_content = ""
        if global_context.plan_path:
            try:
                plan_path = Path(global_context.plan_path)
                if plan_path.exists() and plan_path.is_file():
                    plan_content = plan_path.read_text()
                    logger.info(f"Read plan file: {global_context.plan_path} ({len(plan_content)} characters)")
                else:
                    logger.warning(f"Plan file not found or not a file: {global_context.plan_path}")
            except Exception as e:
                logger.error(f"Failed to read plan file: {e}")

        # If no plan content, use document text as fallback
        if not plan_content:
            plan_content = document_text
            logger.info("Using document text as plan content (no plan file provided)")

        # Invoke question identifier to find ambiguities
        logger.info("Invoking DSPy question identifier")
        ambiguity_result = self.question_identifier(
            relevant_code_context=combined_context,
            current_plan=plan_content
        )

        # Convert output questions to QUESTION cards
        cards = []
        if ambiguity_result.output_ambiguities_questions:
            logger.info(f"Identified {len(ambiguity_result.output_ambiguities_questions)} ambiguities/questions")
            for i, question in enumerate(ambiguity_result.output_ambiguities_questions, 1):
                card = Card(
                    header=f"Question {i}",
                    text=question,
                    type=CardType.QUESTION,
                    metadata={
                        "source": "ambiguities",
                        "plan_path": global_context.plan_path,
                        "question_number": i
                    }
                )
                cards.append(card)
        else:
            logger.info("No ambiguities or questions identified")

        logger.info(f"Generated {len(cards)} question cards")
        return cards

    def _combine_search_results(self, search_results: List[SearchResult]) -> str:
        """
        Combine multiple SearchResult objects into a single formatted string.

        Args:
            search_results: List of SearchResult objects

        Returns:
            Formatted string containing all search results
        """
        if not search_results:
            return "No search results available."

        combined_parts = []
        for i, result in enumerate(search_results, 1):
            if result.success and result.matches:
                combined_parts.append(f"=== Search Query {i}: {result.query} ===")
                combined_parts.append(result.to_formatted_string())
                combined_parts.append("")  # Empty line between results

        if not combined_parts:
            return "All searches returned no results."

        return "\n".join(combined_parts)

    def _build_cursor_context(self, lines: List[str], line: int, col: int) -> str:
        """Build cursor context window with <cursor> marker."""
        if line < 0 or line >= len(lines):
            return "<cursor>"

        current_line = lines[line]
        # Insert <cursor> marker at column position
        before_cursor = current_line[:col]
        after_cursor = current_line[col:]
        context_line = before_cursor + "<cursor>" + after_cursor

        # Try to include surrounding lines if within 150 char limit
        context = context_line
        if line > 0:
            prev_line = lines[line - 1]
            if len(prev_line + "\n" + context) <= 150:
                context = prev_line + "\n" + context

        if line < len(lines) - 1:
            next_line = lines[line + 1]
            if len(context + "\n" + next_line) <= 150:
                context = context + "\n" + next_line

        return context[:150]

    async def is_available(self) -> bool:
        """Check if ambiguities fulfiller is available."""
        from utils import get_lm
        lm_available = get_lm() is not None
        ripgrep_available = await self.search_backend.is_available()
        available = lm_available and ripgrep_available
        logger.info(f"Ambiguities fulfiller availability check: LM={lm_available}, ripgrep={ripgrep_available}, overall={available}")
        return available
